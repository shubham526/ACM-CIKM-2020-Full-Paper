\section{Introduction}
\label{sec:Introduction}




A journalist is writing an article on the recent Coronavirus Disease 2019 (COVID-19)
pandemic in which she analyzes the different angles of the pandemic on the economy and worker's safety. COVID-19 has been widely discussed widely in the news, social media, and research commentary. So for a journalist that has to sift through hundreds of thousands of associated texts  which discuss many different aspects of COVID-19 ranging from transmission, pathology, experimental treatment, to food safety, protests, and stay-at-home-orders. The journalist finds it challenging to identify different texts that are relevant for her article without being overwhelmed with other aspects of COVID-19. One relevant text passage is displayed in Figure \ref{fig:introexample}, top. 


\input{intro-example}


For such support systems, entity linking tools \cite{ferragina2010tagme,mendes2011dbpedia,piccinno2014wat} identify and disambiguate entity mentions, such as of the entity Coronavirus Disease 2019. However the resulting entity links do not differentiate between different aspects of the entity that are being discussed. The journalist in the motivating example would be best helped with a fine-grained extension of entity links---we call this task entity aspect linking. Given a catalog of aspects for each entity, entity aspect linking  additionally extracts which aspect of an entity is referred to in the context. 

 Figure \ref{fig:introexample} lists the most relevant entity aspects for the entities mentioned in the text above.  In this example, a catalog of entity aspects are derived from sections in the Wikipedia article of the mentioned entity, but this is not the only way to define such aspects. 


\ld{Deleted Paragraph. I am not a fan of jobs and apple. If you later need an example to explain entity linking you can move it there -- in the introduction I would focus on stuff that's not very well known.}
% Entity Linking is the task of automatically annotating mentions of entities in text and linking them to their knowledge base entries. Given a sentence such as \textit{Steve Jobs founded Apple}, entity linking tools first aim to identify the entities in the sentence (such as \textit{Steve Jobs} and \textit{Apple}), and then to disambiguate the entity mentions (does the mention \textit{Apple} refer to the fruit or the company?). Finally, they link the mention to its knowledge base entry. For example, the mention \textit{Apple} would be linked to the knowledge base entry for \textit{Apple\_(Company)} and not \textit{Apple\_(Fruit)}.

% Consider a journalist  writing a report on the recent COVID-19 pandemic who wants to analyse the different angles in which it has been mentioned on social media such as the tweet \textit{Several states are seeing outbreaks of \#COVID19 in meat and poultry processing facilities}. To them, identification and disambiguation of the entity \textit{COVID-19} in text may not be enough. They would also want to know the different roles the entity plays. For example, does the mention of COVID-19 in the tweet above refer to its \textit{transmission}, \textit{pathology}, or \textit{experimental treatment}? 

\ld{Merged paragraphs below.}
% Current entity linking tools \cite{ferragina2010tagme,mendes2011dbpedia,piccinno2014wat} can correctly identify and disambiguate entities in text. However, they cannot infer the correct \textit{aspect} of the entity from the context. For example, given the sentence, \textit{Boris Johnson is back after recovering from COVID-19}, an entity linking tool can correctly disambiguate and link the mention \textit{Boris Johnson} to its knowledge base entry but cannot infer whether the mention refers to his role as a \textit{Writer at the Daily Telegraph} or as the \textit{Prime Minister of the UK}. In general, an entity mention may be related to several different events, roles, and topics. We refer to each of them as an \textit{Entity Aspect}. 
\paragraph{\textbf{Task.}} Given an entity-mention $E_M$ in a specific context $C$ such a tweet, sentence or paragraph, and a set of $N$ predefined aspects $A_{E_M} = \{A_1, A_2, A_3, \cdots, A_N\}$ along with their contents. Link the mention to an aspect $A_i \in A_{E_M}$ that captures the addressed topic. 

\bigskip
\ld{I keep on referring to context and content, I think we need a figure for that.}


In the following we distinguish between context and content: the context is the text surrounding the entity mention we seek to aspect-link. With content, we refer to content associated with the aspect.

Nanni et al. \cite{nanni2018entity} introduced the entity aspect linking task and suggested a combination of text similarity metrics between mention context and aspect content. One of the similarity metrics includes the overlap and similarity of other entities mentioned in context and aspect content. However, their approach would assign all entities the same importance weight.

We believe the approach can be improved by incorporating the entity saliency, entity relatedness, and joint aspect linking.  

In context and content, only few entities are salient while most other entities are mentioned in passing, such as in examples, circumstantial references, or clarifications. Approaches for entity salience detection have been developed  recently \ld{cite Dunnietz, cite Xiong, cite SWAT}.  \ld{I made this up, can someone confirm:} In an initial analysis we found that that aspect linking suffers from false-positive aspects which are introduced by spurious entity matches. In this work we explore to which extent salience detection can avoid false positives.
\ld{If we move the salience examples into background, we can say here something like "A detailed introduction to entity saliency is given in Section (Background)".}


Several entity relatedness measures have been suggested \cite{ristoski2016rdf2vec} \ld{add citations}. Given two entities, the entity relatedness measures predict which entities are more likely to be similar. Available entity relatedness tools are pre-trained from knowledge graphs and do not take the context of the entity mention into account. Nevertheless, we believe that a static entity-relatedness measure will provide robust background knowledge when integrated with indicators from context and content.

The success of modern entity linking tools lies in the integration of contextual entities and their relations in the prediction process \ld{need citations, eg. Karma paper from Johannes Hoffart and Gerhard Weikum, Lev Ratinov's Wikifier paper, Tagme}. In this paper we incorporate this idea into Entity Aspect Linking: after predicting the aspect-links of entities in the context, we use aspect-to-aspect similarity indicators to improve the aspect linking result of a selection mention. While knowledge graphs naturally provide relations between entities, they are not suitable for describing the relations between entity aspects. Therefore we explore aspect-to-aspect similarities based on headings, content, and entities. We utilize these similarities to infer the relevance of a particular mention given the context of the linked co-occuring entities.
 
Finally, we reproduce the implementation of Nanni et al.\ and explore several avenues for improvement.


%Nanni et al. \cite{nanni2018entity} have shown that a supervised combination of various text and entity features based on embeddings of the words and entities from various sources (context of mention, content of Wikipedia page of the mention, etc) is able to correctly predict aspects in 70\% of the cases. In this work, we build on their work and use entity salience and relatedness based features in supervised setting with some lexical and semantic features used in \cite{nanni2018entity} and show that this leads to significant improvements in results on the task.

\paragraph{\textbf{Contributions.}} 

%This paper studies the role of entity salience and relatedness on the aspect linking task. We study how these indicators can help and under what conditions they work. We show that using these indicators alone may not be useful but a supervised combination of salience and relatedness based features along with some lexical and semantic features outperforms the current state-of-the-art on the task. We also study the effect of using the frequency and relatedness 
%contextual entities on the task.

Our contributions are as follows.
\begin{enumerate}

    \item We study the effect of using entity salience, entity relatedness and co-occurring entities on the task.
    \item We show that although entity salience and entity relatedness can work on their own, a supervised combination of these indicators along with some lexical and semantic features can outperform several baselines and the current state-of-the-art on the task to achieve better results.
    \item \ld{Jordan: add}
    \item We present a detailed study and analysis of the conditions under which these indicators work versus do not work. 
    \item We offer a reproduction and reimplementation of the entity aspect linking method of Nanni et al.
\end{enumerate}

\paragraph{\textbf{Outline.}} The remainder of this paper is organized as follows. Section \ref{sec:Related Work} discusses some related work on the topic. Section \ref{sec:Approach} presents our proposed method in detail. Section \ref{jordan-logistic} introduces the logistic model used in predicting aspect relevance, while Section \ref{jordan-lstm} uses a Bi-LSTM model to predict aspects embedded using ELMo. In Section \ref{jordan-co-entity}, we motivate the use of co-occuring entities in predicting the relevant of aspects in a joint learning model.  Section \ref{sec:Evaluation} presents a quantitative evaluation of our work. Finally, we conclude the paper with Section \ref{sec:Conclusion}.
