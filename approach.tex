\section{Approach}
\label{sec:Approach}
Our goal is to enrich entity links with fine-grained aspects of the entities. In this work, we consider whether a static measure of entity salience and relatedness which has not been trained for this task can help.  We refer to the entity that we want to link to the correct aspect link as the \emph{target entity}. In the following, we discuss several ideas as micro-approaches. In the evaluation, we will compare them on their own, and through a supervised combination that uses each as a feature.

%\ld{We should prepare the reader in terms of why we are defining features. Maybe with a sentence like this "In the following we discuss several ideas a micro-approaches. In the evaluation we will compare them on their own, an through a supervised combination that uses each as a feature. }


%To study the role of entity salience, entity relatedness and co-occurring entities, we describe below several ranking strategies based on these and later combine them in a learning-to-rank system. In all our discussions, we refer to the entity that we are trying to aspect link as the target entity.

\subsection{Reproduction of Nanni's Method}

We reimplemented Nanni et al's features as described in background. We will include a reproducibility study on his method. Furthermore, these are the basis of our approach in comparison to which we evaluate the utility of entity saliency and entity relatedness.

%Additional we further include a \ld{todo, motivate and describe here} BiLSTM feature. \ld{also explain that we are using elmo}


% \subsection{Neural Methods.}
% We use the PyTorch library \cite{pytorch} to construct our neural networks. There are three neural networks that we consider both independently, and together in a joint model. 


\subsection{Entity Salience for Aspect Linking}
\label{subsec:Entity Salience for Aspect Linking}
Our first extension is to incorporate indicators from entity salience detection.
%\ld{needs a reminder such as "Our first extension is to incorporate indicators from entity salience detection."}

\input{salience-motivation}
We hypothesize that entity salience is a useful indicator of aspects for entities. We use SWAT \cite{swat}  to find the salience of an entity in text. Given some text, SWAT outputs the entities along with their salience scores in the text. For example, using the online demo \footnote{https://swat.d4science.org/}, given the two passages in Figure \ref{fig:Salience}, SWAT correctly predicts \textit{Boris Johnson} as salient in Passage 2 (Score = 0.6), and non-salient in Passage 1 (Score = 0.15). 
We use salience detection in our aspect-linking approach by incorporating the following indicators.

%\ld{Needs a sentence such as "We use salience detection in our aspect-linking approach by incorporating the following indicators."}

\begin{enumerate}
    \item \textbf{Salience of Entity Mention in aspect (Sal-EM).} Score of the aspect is equal to the salience score of the entity mention in the aspect if the entity is salient, and zero otherwise.
    
    \item \textbf{Salient Entities in Context (SEC).} Score an aspect by summing over the salience score of entities $e \in E$, where $E = E_A \cap E_C$, $E_A =$ aspect entities, and $E_C =$ salient entities in sentence, paragraph and section context.
    
    \item \textbf{All Entities in Context (AEC).} 
    To investigate the extent to which salient entities can affect the performance, we also experiment with using both salient and non-salient entities from SWAT for $E_C$ in \ref{subsec:Entity Salience for Aspect Linking}(2) above. 
\end{enumerate}


\subsection{Entity Relatedness for Aspect Linking}
\label{subsec:Entity Relatedness for Aspect Linking}

%\ld{Fede was using the entity relatedness measure "RDF2Vec", we replace this with other Entity Relatedness measures like in SWAT. However, we need to explain why we changed this. For example we can say that Rdf2Vec did not work as well, but that is a claim we need to substantiate with evidence. @jordan was playing around with Rdf2vec but did not get good results, maybe we can include some of these 'bad' results to support our point?  @shubham maybe you can get some of the Rdf2Vec results and say a few words about how they differ.  I can imagine that RDF2Vec does not work so well, because it is trained on typed  relations available in DBpedia, but these are mostly about people, organizations, and places. I don't know what SWAT is trained on, but even if it is hyperlinks on Wikipedia, it has a better chance of working in our "open-domain" topic.  --- Of course this is speculation, but if we can substantiate the speculation, it would make this paper even stronger. }


Entity Relatedness is a measure of how strongly related two entities are. For example, consider the entities, \textit{Boris Johnson}, \textit{Theresa May}, and \textit{Donald Trump}. Intuitively, one would say that \textit{Boris Johnson} is more strongly related to \textit{Theresa May} than to \textit{Donald Trump} because both \textit{Boris Johnson} and \textit{Theresa May} are British politicians and had some role in Brexit. We hypothesize that this measure of entity relatedness can help in aspect linking. More concretely, we hypothesize that an aspect mentioning many related entities to the target entity  is a good candidate for an aspect for the given target entity. For example, consider the aspect about \textit{Boris Johnson} pertaining to his role as the \textit{Prime Minister of UK} during the COVID-19 pandemic as given in Figure \ref{fig:relatedness-example}.

\begin{figure}[t]
    \centering
    \begin{quote}
        \textbf{Aspect.} Prime Minister of UK \\
        \textbf{Content.}
         Former Prime Minister Theresa May has criticised world leaders for failing "to forge a coherent international response" to the coronavirus pandemic. Mrs May's intervention comes as Boris Johnson and Sir Keir Starmer face each other at Prime Minister's Questions for the first time later. \footnote{https://www.bbc.com/news/uk-politics-52553237}.
    \end{quote}
    \caption{Example aspect with content to depict entity relatedness intuition.}
    \label{fig:relatedness-example}
\end{figure}

The aspect in Figure \ref{fig:relatedness-example} may be linked to the entity \textit{Boris Johnson} since it mentions several related entities such as \textit{Theresa May} and \textit{Sir Keir Starmer}. 


Co-occurring entities are entities which co-occur with a given entity in a particular context such as a sentence, passage or article. For example, entities which might co-occur with \textit{Boris Johnson} in a passage may be \textit{Theresa May}, \textit{United Kingdom} and \textit{Brexit}. We study the role of such co-occurring entities on the aspect linking task by comparing whether the frequency or relatedness of these co-occurring entities to the target entity is a better indicator of aspects and under what conditions they work. 


\subsubsection{Co-occurring entities with an entity from context}
\label{subsubsec:Co-occurring entities with an entity from context}

% For every entity $e$ in the sentence, paragraph and section context around the target entity $e_T$, we derive a distribution over co-occurring entities $e'$
% with $e$ using the frequency of co-occurrence and the relatedness of co-occurring entities to $e$. We may treat this distribution as the conditional probability distribution $P(e' \vert e)$. To find the co-occurring entities, we use the Entity Context Document (ECD) \cite{chatterjee2019why} for $e$. The ECD is created by first retrieving a candidate set of passages using $e$ as the query and then concatenating all passages which mention $e$.
% We score an aspect $A$ in following ways.

% \begin{enumerate}
%     \item \textbf{Simple Frequency Distribution (SF-Dist).}
    
%     We score aspects using frequently co-occurring entities with an entity $e$ from the sentence, paragraph and section context around the target entity, which also occur in the aspect content. Formally,:
%     \begin{equation}
%     \label{eq:score-aspect-using-simple-freq-dist}
%         \text{Score(A)} = \sum_{e' \in A}P(e' \vert e)
%     \end{equation}
%     where $e'$ is an entity in the aspect $A$ which also frequently co-occurs with $e$, $e$ is an entity from the context around the target entity, and $P( e' \vert e)$ is the frequency distribution over co-occurring entities.
    
%     \item \textbf{Weighted Frequency Distribution (WF-Dist).} 
    
%     Our intuition is that co-occurring entities which are more related to the target entity should contribute more to the final aspect scores. To investigate how relatedness of co-occurring entities affects the aspect scores, we experiment with scoring an aspect $A$ using a weighted sum of frequencies of entities $e'$ in the aspect, weighted by the relatedness of $e'$ to the target entity $e_T$. Formally,
%     \begin{equation}
%         \label{eq:score-aspect-using-weighted-freq-dist}
%         \text{Score(A)} = \sum_{e' \in A} \text{Relatedness}(e', e_T) \times P(e' \vert e)
%     \end{equation}
%     where $e'$ is an entity in the aspect $A$ which also frequently co-occurs with $e$, $e_T$ is the target entity, $e$ is an entity from the context around the target entity $e_T$, and $\text{Relatedness}(e', e_T)$ is found using WAT \cite{piccinno2014wat}.

The method of Nanni et al. uses exact matches of contextual entities $e'$ in the context and aspect content. However since there are only few such entities, we explore methods to derive an expanded set of prominent entities $e'$, then rank aspects by how frequently they match these most prominent entities $e'$. 

For every entity $e$ in the context of the target entity $e_T$ (sentence, paragraph or section), we retrieve top $k$ passages from a background corpus using $e$'s name as a query. (For the evaluation we arbitrarily chose $k=100$, results of other contexts will be made available in an online appendix). We construct a bag of potential expansion entities (henceforth called PROM in this paper) from all entities mentioned in all $E \times k$ passages that were retrieved through $E$ queries, one for each contextual entity $e$. We calculate the frequency $\text{tf}_{e}(e')$ with which entities occur in the passage ranking for entity $e$ as follows:

\begin{equation}
\label{eq:frequency-of-co-occurring-ent}
    \text{tf}_{e}(e')=\sum_{p\in P_e}\text{tf}(e'\vert p)
\end{equation}
where $P_e$ are the passages mentioning $e$ in the passage ranking obtained using $e$ as query and $\text{tf}(e'\vert p)$ is the frequency of $e'$ in $p$.
%
From this frequency, we derive a prominence $P(e'\vert e_T)$ and use it to reweigh entities in this bag. The prominence not only incorporates the degree of association of $e'$ with the contextual entity $e$, but also how consistently $e'$ is associated with other entities $e$ that occur in the context we seek to link. Akin to language models, the term frequency $\text{tf}_{e}(e')$ is normalized to sum to one over all context entities $e''$.

    \begin{equation}
    \label{eq:prominence}
        P(e' \vert e_T) =  \frac{1}{E} \sum_e  \sum_{e'} \frac{\text{tf}_{e}(e')}{\sum_{e''}\text{tf}_{e}(e'')}
    \end{equation}



Finally, we match prominent entities $e'$ in target aspects $a$: the more frequent  prominent entities $e'$ are mentioned in the aspect content, the higher the aspect is ranked. 

    \begin{equation}
    \label{eq:score-aspect-using-simple-freq-dist}
        \text{Score(a)} = \sum_{e' \in a}P(e' \vert e_T)
    \end{equation}



We explore three variants of this approach.

\begin{enumerate}
     \item \textbf{Simple Frequency Distribution (SF-Dist).}
     Using the prominence score $P(e' \vert e_T)$ produced via passage ranking of all entities $e$ mentioned in the context.

This co-occurrence-based entity scoring metric allows us to match more entities $e'$ in the aspect than solely using entities in the context $e$. However, as any expansion approach, it is prone to promote spurious matches. 
 
 \item \textbf{Weighted Frequency Distribution (WF-Dist).} 
 To remedy the promotion of spurious matches, we combine the prominence score with an entity-relatedness score between entities $e'$ and the target entity $e_T$.
 
 \begin{equation}
         \label{eq:score-aspect-using-weighted-freq-dist}
        \text{Score(a)} = \sum_{e' \in a} \text{Relatedness}(e', e_T) \cdot P(e' \vert e_T)
    \end{equation}


\item \textbf{Relatedness Distribution (Rel-Dist).} 
Same approach as in Equation  \ref{eq:score-aspect-using-weighted-freq-dist} but the prominence score is ignored. We only use the prominence approach to select a set of entities $e'$. 

\end{enumerate}

\subsubsection{Co-occurring entities with the target entity} 
\label{subsubsec:Co-occurring entities with the target entity}

Since contextual entities $e$ might be less well suited than the target entity $e_T$, we explore several methods that emphasize a connection to the target entity.



%We use two sources of co-occurring entities with the target entity $e_T$: Entity Context Document (\textbf{ECD}) for $e_T$ and the Wikipedia page (\textbf{Wiki}) of $e_T$. We then score an aspect using the co-occurring entities with $e_T$ in two ways.

    %\ld{do you have a naming convention to distinguish methods from 4.3.1 (contextual) from these here (focused on target entity)? }
\begin{enumerate}
    \item \textbf{Rel-Dist-PROM.} Using the prominence approach from Section \ref{subsubsec:Co-occurring entities with an entity from context}(3), but building an entity set only for the target entity $e_T$, while ignoring other contextual entities $e$.
    \item \textbf{Rel-Dist-Wiki.} Instead of identifying entities through other passages, we consider entities $e'$ mentioned on the Wikipedia page of the target entity $e_T$. These entities $e'$ are ranked by relatedness to $e_T$.
\end{enumerate}

Instead of ranking aspects $a$ by a sum of prominence/relatedness scores that they contain, we invert the approach and rank aspects by retrieval models. The query is formed by the title of the target entity which is expanded with top 20 entities $e'$ --- these are weighted in the query akin to RM3 \cite{lavrenko2001relevance}. We explore weighted combinations of the following retrieval models as implemented in Lucene: (1) BM25 (default parameters), (2) Language Models with Jelinek-Mercer (LMJM) smoothing $(\lambda = 0.4)$, and (3) Language Models with Dirichlet (LMDS) smoothing, with both RM1 and RM3 expansion models on entities.


    
%    from Equation  \ref{eq:score-aspect-using-simple-freq-dist} with either frequency distribution \textbf{(SF-Dist-ECD)} or relatedness distribution \textbf{(Rel-Dist-ECD/Rel-Dist-Wiki)} over co-occurring entities to score an aspect.
\begin{enumerate}        
    \item \textbf{RS-Asp-Freq-PROM.} Expand query weighted by prominence score and retrieve aspects.
    \item \textbf{RS-Asp-Rel-PROM.} Expand query weighted by relatedness score and retrieve aspects.
    \item \textbf{RS-Asp-Rel-Wiki.} Expand with top 20 entities by relatedness (to $e_T$) on Wikipedia page of $e_T$ and retrieve aspects.
\end{enumerate}




 


\begin{comment}
We give a brief overview of the same again for reference. 

Nanni et al.\cite{nanni2018entity} consider three types of aspect representations for finding its similarity to the entity mention in context. 

\textbf{Header.} Rank aspects based on similarity of the mention in context to the header of each section in the Wikipedia page.

\textbf{Content.} Rank aspects based on the similarity between the mention in context and the content of each section of the Wikipedia page of the entity.

\textbf{Entity.} Overlap of entities mentioned in the context of the entity mention and the content of a section on the Wikipedia page of the entity.

They use the following features to rank aspects using the representations above.

\textbf{TF-IDF.} Cosine similarity between the TF-IDF (logarithmic, L2-normalized) vector of contextual mention and aspect.

\textbf{BM25.} Rank aspect representations using the contextual mention as a query using BM25 ($k_1=2, b=0.75)$.

\textbf{Word Embeddings.} Cosine similarity between the mention in context and
the aspect using pre-trained GloVe \cite{pennington2014glove} embeddings of dimension 300. 

\textbf{Entity Embeddings.} Use 500 dimensional RDF2Vec \cite{ristoski2016rdf2vec} embeddings to embed entities in the context of the entity mention and a section from the Wikipedia page of the entity, then compute
the document vector using the TF-IDF of an an entity in context of the entity mention and its embedding.
\end{comment}