%
% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,authordraft]{acmart}
\usepackage{booktabs}
\usepackage{verbatim}
\usepackage{graphicx}

 %activate todo's
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}\PackageWarning{TODO:}{#1!}}
% deactivate todos
%\newcommand{\todo}[1]{ \PackageWarning{TODO:}{#1!}}

%
% defining the \BibTeX command - from Oren Patashnik's original BibTeX documentation.
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
% Rights management information. 
% This information is sent to you when you complete the rights form.
% These commands have SAMPLE values in them; it is your responsibility as an author to replace the commands and values with those provided to you when you complete the rights form.
%
% These commands are for a PROCEEDINGS abstract or paper.
\copyrightyear{2018}
\acmYear{2018}
\setcopyright{acmlicensed}
\acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection, June 03--05, 2018, Woodstock, NY}
\acmPrice{15.00}
\acmDOI{10.1145/1122445.1122456}
\acmISBN{978-1-4503-9999-9/18/06}


\begin{document}

\section{Background}


\subsection{Co-Entity Context}\label{jordan-co-entity}
One valuable source of context for which we can use to link an aspect to an entity mention, is that entities can be mentioned together in the same paragraph.
We can use this context to further evaluate the relevance of aspects, given how much they have in common with the aspects of entities that co-occur in the same passage. 

For example, the Chocolate Wikipedia page contains many sections that cover a broad array of subtopics. One of these sections is the ``Health Benefits of Chocolate'', which is notably smaller than the other sections in comparison. The section contains very specific medical terms that may not occur in a sentence where this section would be the correct aspect to link to. As an example, consider a sentence like ``Make sure that you keep away chocolate from your dogs.''. There is no indication that this has anything to do with health, but if we first linked the aspect of dogs, we would see that the ``Health'' section explicitly mentions the danger of poisoning from chocolate. Using this context, it then becomes clear what the relevant section is in Chocolate: not the section that mentions chocolate the most, but the one that talks about Theobromine poisoning and side effects.

\textbf{Aspect Relevance.} Our task requires that we choose the aspect that best explains the context of an entity mention. We use a measure of relevance to represent the likelihood that an entity aspect should be linked to an entity given a mention and its surrounding context.

\textbf{Co-Entity Similarity}. It is not always the case that we can use the context of co-entities to infer the context of an entity mention. For example, a very large paragraph can contain many co-entities that are spaced far apart. We would expect distance entities to share little context in common.
We use measures of similarity between co-entities and entities to determine how much context they share in common.

\textbf{Co-Aspect Similarity.}. One drawback of the Co-Entity similarity measure is that it is more of a global measure of contextual similarity. Consider the ``Chocolate'' example in section \ref{jordan-disambig}. Dogs and chocolates are not very related to each other, although we saw a context in which these two entities were related to each other, and that's the fact that chocolate is poisonous to dogs. Both entities have a section discussing this fact, but these sections are far smaller than the other sections in these entities by comparison. In the case of a global measure of inference, we would expect there to be a very weak correlation between chocolate and dogs, as they possess few overlapping topics. If we instead looked at the individual sections in each page, we would see that the ``Health'' section in ``Dog'' frequently mentions the dangers of chocolate and theobromine poisoning. 

\section{Approach}


\subsection{Entity Aspect Representation}\label{jordan-vector}
In this paper we represent entity aspects in two ways.
The first way is through the use of features which measure the relevance of an entity aspect with respect to the paragraph context of an entity mention. We use the following following aspect relevance features:

\textbf{bm25-\{sentence / paragraph\}-to-text}. We use the BM25 to compare an entity aspect's main body of text to the sentence, or paragraph, that contains the entity mention. 

\textbf{bm25-\{sentence / paragraph\}-to-header}. We use the BM25 to compare an entity aspect's section header to the sentence, or paragraph, that contains the entity mention. 


\textbf{entity-overlap-\{sentence / paragraph\}}. We count the number of distinct entity overlaps between an entity aspect and the entities contained in the sentence, or paragraph, that contains the entity mention.

\textbf{word2vec-\{sentence / paragraph\}-cosine}. We use the Word2Vec embedding to measure the cosine similarity between the text of an entity aspect, and the text of the sentence, or paragraph, that contains the entity mention.

\textbf{aspect-size}. This length of an entity aspect text in words.

... 

(\textit{actually maybe I should just cite Fede's features and say I used those})

...

The second way in which we represent entity aspects is through embeddings using ELMo \cite{elmo}.
ELMO's is a contextual language embedding model that takes as input a sentence, and outputs word embeddings that depend upon the context given by the sentence. Each word embedding consists of three vectors, and in this paper we concatenate these vectors together to obtain a final word embedding. We then average all of the word embeddings in a sentence together to obtain the embedding of a sentence. These embeddings are used as sequential inputs in a BiLSTM. We embed both the paragraph context of an entity's mention, and the text of each candidate entity aspect. (number of hidden layers to be determined ...)

\subsection{Neural Methods.}
We use the PyTorch library \cite{pytorch} to construct our neural networks. There are three neural networks that we consider both independently, and together in a joint model. 

\subsection{Logistic Network}

The logistic network consists of an input layer, which takes the entity aspect ``bag of words'' vectors as an input, a single linear layer, and an output layer that represents the likelihood that the entity aspect is the correct aspect to link to a given entity mention. There are three separate versions of this network that we utilize throughout this paper. 


\subsection{BiLSTM Network}
 The sentence embeddings of both the entity aspects, and the paragraph context in which an entity mention is located, are used as inputs into two separate BiLSTM layers. The outputs of the BiLSTMs are concatenated and a final linear transformation is used to obtain a scalar value that also represents the likelihood of an entity aspect being the correct aspect to link to a given mention.
 
...
 
 (T.B.D. if BiLSTM approach works with new dataset; may drop if numbers aren't good)
 
 \subsection{Global Context Network}
The global context network utilizes entities that co-occur within the same text as the primary entity mentions. We do not possess a ground truth for the majority of these co-occuring entities because most links in Wikipedia do not link to a section in a page. However, these co-occuring entities are still useful in determining the likelihood that a primary entity aspect aspect should be linked. 
We accomplish this by scoring each pair of co-occuring entity aspect and primary entity aspect with respect to a set of aspect-to-aspect similarity functions. Each similarity function therefore generates an I by J by K matrix, where I is the number of co-occuring entities, J is the number of co-occuring entity aspects which is padded to maintain a size of 20, and K is the number of primary entity aspects. We use the following aspect-to-aspect similarity functions:

\textbf{Unigram Overlap.} The number of unigrams that overlap based on the text contained in each entity aspect.


\textbf{Character n-gram Overlap.} We use a sliding window to generate character 4-grams from each entity aspect text, and the similarity between to entity aspects is respect to the overlap of these 4-grams.

\textbf{Header Overlap.}
We also use the Character n-gram Overlap method with respect to the section header of each entity aspect.

\textbf{Entity Overlap.}
Each entity aspect also contains a number of entity links within the main body of its text. We count the overlap of these entities with respect to two entity aspects.

\textbf{Word2Vec Cosine Similarity.} 
We embed the text of each entity aspect by using Word2Vec to generate word embeddings, and then we average these embeddings together. We measure the cosine similarity between two entities with respect to these embeddings.

We then score the relevance of an entity aspect using a weighted combination of these aspect-to-aspect similarity features.  
Let $a^{'}$ be an entity aspect, $E$ be the collection of co-entities for a given paragraph context, $A_i$ be the set of co-entity aspects with respect to a given co-entity, $e_i$, $S$ be the collection of aspect-to-aspect similarity features, and $\lambda_j$ be a weight for aspect-to-aspect similarity feature $\lambda_j$. Finally, we also utilize a logistic layer to represent the relevance of a co-aspect with respect to a co-entity, given by the function $\text{rel}(e_i, a_j)$. 

\begin{equation}
\text{global}(a^{'}) = \sum_{e_i  \in E}\sum_{a_j \in A_i}\sum_{\text{sim}_k \in S} \text{rel}(e_i, a_j) \cdot \text{sim}_k(a^{'}, a_j) \cdot \lambda_j
\end{equation}

\subsection{Joint Learning}
...(T.B.D. on what works; two different approaches)


\section{Evaluation}
We evaluate the Logistic Network, BiLSTM network, and Global Context Separately, as well as together with respect to joint optimization. We train each model with respect to binary cross entropy, using the Adam optimizer from the PyTorch library. We use samples from the 88k dataset, and then evaluate with respect to the samples in Nanni et al.'s dataset. We report P@1 and MAP statistics for each method. The \textbf{just-logistic, just-bi,} and \textbf{just-global} methods are with respect to evaluation using only the logistic network, BiLSTM network, and global context network respectively. The \textbf{joint-network} method consists of all three networks, the parameters of which are trained simultaneously.

% \bibliographystyle{ACM-Reference-Format}
% \bibliography{references}
\end{document}