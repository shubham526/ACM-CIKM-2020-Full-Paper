
\subsubsection{Entity Salience}
\label{subsubsec:Entity Salience}
%\textbf{RQ1: Entity Salience.}

\paragraph{\textbf{Observations.}}
We observe from Table \ref{tab:Results-shubham} that a supervised combination of all salience features (Subset-2) outperforms 2 of the 4 baselines, whereas a combination of all salience features with the lexical and semantic features (Subset-4) outperforms all baselines. However, considering all entities (salient and non-salient) in the context (AEC Sentence) performs better than considering only the salient entities (SEC Sentence). We also find that in Subset-2, learning-to-rank always places maximum weight on the AEC methods.

\paragraph{\textbf{Discussions.}}
These observations show the effectiveness of using salience. However, they also indicate that considering non-salient entities together with the salient ones help improve performance. To investigate this further, we manually confirmed that SWAT correctly identifies salient entities in text. However, SWAT returns more empty results when asked for only salient entities than when asked for all (salient or otherwise) entities. For example, using the sentence context of an entity mention, it returns an empty result for 100 of the 201 entity mentions when asked for only the salient entities and 13 of 201 entity mentions when asked for all  entities. This shows the limitations in SWAT and why the results obtained using \textit{SEC (Sentence)} is lower than \textit{AEC (Sentence)}.  Our intuition is that the other entities, although non-salient, have some inherent semantic meaning and hence considering them together with the salient entities helps the task. This is the case for the paragraph and section contexts too but we do not show the results here due to space constraints. 

Moreover, in Section \ref{subsec:Entity Salience for Aspect Linking}, we match the salient entities in the context to (1) salient entities in the aspect (SEC), and (2) all entities in the aspect (AEC). Matching through SEC gives us very few entities for the aspect, whereas matching through AEC gives us more entities. However, the entities obtained through SEC are salient whereas a lot of entities obtained through AEC are not important (non-salient). Ideally, one would train a L2R model to learn how much weight to put on each alternative. Here we present an additional experiment where we produce an entity ranking for each aspect using four alternatives: (1) Match salient entities in context to salient entities in aspect, (2) Match salient entities in context to all entities in aspect, (3) Match all entities in context to salient entities in aspect and (4) Match all entities in context to all entities in aspect. We evaluate these entity rankings using a ``ground truth" of aspects where we define any entity mentioned in the aspect as relevant for the aspect. The results are shown in Table \ref{tab:Results-Entity-Rankings-Sal}. 

\input{salience-example}

We observe in Table \ref{tab:Results-Entity-Rankings-Sal} that matching all entities in context to all entities in aspect works the best. This is expected because as discussed above, we lose a lot of entities when asking SWAT for only salient entities. Moreover, matching salient context entities to all aspect entities works better than matching with only salient aspect entities. For example, matching salient context entities to all aspect entities using sentence context has $\text{MAP}=0.009$, whereas matching with salient aspect entities has $\text{MAP}=0.002$. Although these numbers are not very encouraging, they depict that matching salient context entities to all aspect entities is better. This also shows why AEC outperforms SEC in Table \ref{tab:Results-shubham}.

%we observe that the L2R combination of these entity rankings for each context type performs very poorly.
One issue with matching entities in such an exact way is that very often, there are no matches. In such cases, a lot of aspects receive a score of zero in our methods (SEC and AEC in Section \ref{subsec:Entity Salience for Aspect Linking}). This also shows why the \textit{AEC (Sentence)} outperforms  \textit{SEC (Sentence)} in Table \ref{tab:Results-shubham}. There are more matching entities when matching all aspect entities (as in AEC) than when matching only salient aspect entities (as in SEC), with salient context entities, as evident by the MAP results for methods \textit{Context-Salient-Content-Salient} and \textit{Context-Salient-Content-All} in Table \ref{tab:Results-Entity-Rankings-Sal}. To illustrate this issue, we present an example from the dataset of Nanni et al.\cite{nanni2018entity} that we used in our work in Figure \ref{fig:Salience-Example}. We observe that the entity \textit{Kyoto Protocol} is salient in the context (shown by bold italic) but not in the content (shown by only bold). Hence, SEC would score this aspect zero since there are no matching salient entities, but AEC would not.


To investigate the extent to which salience helps, we divide the entity mentions  into different levels of difficulty according to the performance (P@1) of the \textit{Nanni et al. (Sentence)} method, with the 5\% most difficult queries fo
r this method to the left and the 5\% easiest ones to the right, and compare the performance with the \textit{Subset-4}. The results are shown in Figure \ref{fig:difficulty-plot}. We observe that whenever it is difficult to perform the task using \textit{Nanni et al. (Sentence)}, entity salience supports our L2R system (Subset-2 and Subset-4).


\paragraph{\textbf{Conclusions.}}
With respect to RQ1, we can say that entity salience does indeed affect the task positively. We are able to outperform all the baselines with the help of salience and we see that salience helps to boost performance when the queries get difficult by learning information which is complimentary to the lexical and semantic features. However, exactly matching entities between context and aspect content leads to finding no matches for most aspects and hence most aspects receive a score of zero. Added to this are the limitations of SWAT in finding salient entities. Hence, entity salience is helpful but hindered by we need to know how to use it to help our task.

%We are able to outperform all the baselines with the help of salience and we see that salience helps to boost performance when the queries get difficult. However, SWAT is still limited in its salience detection and this hinders the performance of a system using it. 

%\textbf{RQ2: Entity Relatedness.}
\subsubsection{Entity Relatedness}
\label{subsubsec:Entity Relatedness}

\paragraph{\textbf{Observations.}}
We observe from Table \ref{tab:Results-shubham} that a supervised combination of all relatedness features (Subset-1) does not perform very well on its own, doing better than only one baseline (Size). However, a combination of relatedness features with the lexical and semantic features (Subset-3) does significantly better than 3 of the 4 baselines. Moreover, a combination of salience and relatedness features with the lexical and semantic features outperforms all baselines. 

\paragraph{\textbf{Discussions.}}
These observations indicate that entity relatedness does indeed affect the task positively. However, salience is more informative than relatedness as is evident from the superior performance of Subset-2 over Subset-1 and Subset-4 over Subset-3. On further investigation, we found that WAT finds many false positives and false negatives. For example, given the entity list consisting of  \textit{World War I}, \textit{Vietnam War} and \textit{France}, it predicts that \textit{World War I} is related to \textit{Vietnam War} (false positive) but  unrelated to \textit{France} (false negative). This is because WAT does not take
the query or the context of the entity into account but makes predictions based on certain graph-based features such as number of inlinks and outlinks to and
from a particular entity node in a knowledge graph. 

To investigate the extent to which relatedness helps, we present results from the difficulty test explained in Section \ref{subsubsec:Entity Salience} in Figure \ref{fig:difficulty-plot}. We observe that whenever it is difficult to perform the task using \textit{Nanni et al. (Sentence)}, entity relatedness supports our L2R system (Subset-3 and Subset-5).


\paragraph{\textbf{Conclusions.}}
With respect to RQ2, we may say that relatedness does indeed affect the task positively. Although relatedness of entities by itself may not perform very well, a supervised combination with lexical and semantic features improves performance over several baselines. Moreover, a L2R system containing relatedness based features help to boost performance when queries get difficult. However, the limitations of WAT hinder the performance of a system using it.

%considering relatedness features in combination with some lexical and semantic features can help the task. However, WAT is limited in its entity relatedness system where it finds many false positives and false negatives.

%\textbf{RQ3: Frequency vs Relatedness.}
\subsubsection{Frequency vs Relatedness}
\label{Frequency vs Relatedness}

\paragraph{\textbf{Observations.}}
From Table \ref{tab:Results-shubham}, we observe that ranking aspects using \textit{SF-Dist (Sentence)} outperforms \textit{WF-Dist (Sentence)}, which in turn outperforms \textit{Rel-Dist (Sentence)}). Moreover, \textit{RS-Asp-Freq-ECD} outperforms \textit{RS-Asp-Rel-ECD}. We also find that when L2R is trained on all relatedness features (Subset-1), it places more weight on the features using frequency distribution those using relatedness. 

\paragraph{\textbf{Discussions.}}
These observations indicate that using the frequency of co-occurring entities is more informative than the relatedness. To investigate this further, as in Section \ref{subsubsec:Entity Salience}, we produce entity rankings for every aspect using (1) frequency (SF-Dist in Section \ref{subsec:Entity Relatedness for Aspect Linking}(1)) and (2) relatedness (Rel-Dist in Section \ref{subsec:Entity Relatedness for Aspect Linking}(3)) of entities and evaluate these rankings by defining all entities in an aspect as relevant for the aspect. The results are shown in Table \ref{tab:Results-Entity-Rankings-Freq-And-Rel}.

From Table \ref{tab:Results-Entity-Rankings-Freq-And-Rel}, we observe that the entity rankings obtained using frequency distribution are indeed better (in terms of Mean Average Precision (MAP)) than those obtained using relatedness. For example, entity ranking obtained using section context and frequency distribution has $\text{MAP}=0.13$ whereas that obtained using relatedness has $\text{MAP}=0.04$. We also perform an additional experiment where we analyse the number of aspects that were helped (in terms of MAP) by using frequency distribution of co-occurring entities as compared to using the relatedness distribution. The results are shown in Table \ref{tab:Helps-Hurts-Analysis}. We observe, for example, that using frequency with section context helps 1160 aspects while hurting just 3 as compared to using relatedness. This shows why the entity ranking obtained using frequency and section context performs better than that obtained using relatedness in Table \ref{tab:Results-Entity-Rankings-Freq-And-Rel},and consequently, why the \textit{SF-Dist} methods perform better than the \textit{Rel-Dist} method in Table \ref{tab:Results-shubham}.

\paragraph{\textbf{Conclusions.}}
With respect to RQ3, we may say that using frequency of co-occurring entities is better than using relatedness because most frequently co-occurring entities are also related but most related entities do not frequently co-occur. Moreover, with respect to RQ2, although relatedness can help when the queries get difficult, as compared to frequency, it hurts the performance of a method using it.
