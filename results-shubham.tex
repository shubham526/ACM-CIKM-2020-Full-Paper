
\subsection{RQ1: Entity Salience}
\label{subsec:Entity Salience}
%\textbf{RQ1: Entity Salience.}

\paragraph{\textbf{Observations.}}
We make the following observations from Table \ref{tab:Results-shubham}.
\begin{enumerate}
    \item A supervised combination of all salience features (Subset-2) outperforms two of the four baselines.
    \item A combination of all salience features with the lexical and semantic features (Subset-4) outperforms all baselines.
    \item However, considering all entities (salient and non-salient) in the context (AEC Sentence) performs better than considering only the salient entities (SEC Sentence).
\end{enumerate}
%We observe from Table \ref{tab:Results-shubham} that a supervised combination of all salience features (Subset-2) outperforms two of the four baselines, whereas a combination of all salience features with the lexical and semantic features (Subset-4) outperforms all baselines. However, considering all entities (salient and non-salient) in the context (AEC Sentence) performs better than considering only the salient entities (SEC Sentence). 
We also find that in Subset-2, learning-to-rank always places maximum weight on the AEC methods.

\paragraph{\textbf{Discussions.}}
These observations show the effectiveness of using salience. However, they also indicate that considering non-salient entities together with the salient ones help improve performance. To investigate this further, we manually confirmed that SWAT correctly identifies salient entities in text. However, SWAT returns many empty results when asked for only salient entities than when asked for all (salient or otherwise) entities.
%\ld{"Many passages not contain any detected salient entities, yielding many empty results especially for sentence contexts" instead of} SWAT returns many empty results when asked for only salient entities than when asked for all (salient or otherwise) entities.\ld{cut?} 
For example, using the sentence context of an entity mention, SWAT returns an empty result for 100 of the 201 entity mentions when asked for only the salient entities and 13 of 201 entity mentions when asked for all  entities. 
This shows the limitations of SWAT and why the results obtained using \textit{SEC (Sentence)} is lower than \textit{AEC (Sentence)}.  Our intuition is that the other entities, although non-salient, have some inherent semantic meaning and hence considering them together with the salient entities helps the task. This is the case for the paragraph and section contexts too but we do not show the results here due to space constraints. 

%\subsection{RQ3: Entity Ranking for Aspect Linking}
In Section \ref{subsec:Entity Salience for Aspect Linking}, we match the contextual salient entities to (1) salient entities in the aspect (SEC), and (2) all entities in the aspect (AEC). Matching through SEC gives us very few entities for the aspect, whereas matching through AEC gives us more entities. However, the entities obtained through SEC are salient whereas a lot of entities obtained through AEC are not important (non-salient). 

To study the quality of the entity ranking for aspect matching (\textbf{RQ4}), we train a L2R model to learn the weighted combination for these alternatives:
%Here we present an additional experiment where we produce an entity ranking for each aspect using four alternatives:
\begin{enumerate}
    \item Match salient entities in context to salient entities in aspect.
    \item Match salient entities in context to all entities in aspect.
    \item Match all entities in context to salient entities in aspect.
    \item Match all entities in context to all entities in aspect
\end{enumerate}

%(1) Match salient entities in context to salient entities in aspect, (2) Match salient entities in context to all entities in aspect, (3) Match all entities in context to salient entities in aspect and (4) Match all entities in context to all entities in aspect. 

We evaluate these entity rankings using a ``ground truth'' of aspects where we define any entity mentioned in the aspect as relevant for the aspect. The results are shown in Table \ref{tab:Results-Entity-Rankings-Sal}. 

\input{salience-example}

We observe in Table \ref{tab:Results-Entity-Rankings-Sal} that matching all entities in context to all entities in aspect works the best. This is expected because as discussed above, many entities are missing when only considering salient entities. Moreover, matching salient context entities to all aspect entities works better than matching with only salient aspect entities. For example, matching salient context entities to all aspect entities using sentence context has $\text{MAP}=0.009$, whereas matching with salient aspect entities has $\text{MAP}=0.002$. These numbers are low, because SWAT does not identify salient entities in many contexts. Nevertheless  these results depict the benefits of salient context entities over all aspect entities. This also shows why AEC outperforms SEC in Table \ref{tab:Results-shubham}.

%we observe that the L2R combination of these entity rankings for each context type performs very poorly.
One issue with matching entities in such an exact way is that very often, there are no matches. In such cases, a lot of aspects receive a score of zero in our methods (SEC and AEC in Section \ref{subsec:Entity Salience for Aspect Linking}). This also shows why the \textit{AEC (Sentence)} outperforms  \textit{SEC (Sentence)} in Table \ref{tab:Results-shubham}. There are more matching entities when matching all aspect entities (as in AEC) than when matching only salient aspect entities (as in SEC), with salient context entities, as evident by the MAP results for methods \textit{Context-Salient-Content-Salient} and \textit{Context-Salient-Content-All} in Table \ref{tab:Results-Entity-Rankings-Sal}. To illustrate this issue, we present an example from the dataset of Nanni et al.\cite{nanni2018entity} that we used in our work in Figure \ref{fig:Salience-Example}. We observe that the entity \textit{Kyoto Protocol} is salient in the context (shown by bold italic) but not in the content (shown by only bold). Hence, SEC would score this aspect zero since there are no matching salient entities, but AEC would not.


To investigate the extent to which salience helps, we divide the entity mentions  into different levels of difficulty according to the performance (P@1) of the \textit{Nanni et al. (Sentence)} method, with the 5\% most difficult queries fo
r this method to the left and the 5\% easiest ones to the right, and compare the performance with the \textit{Subset-4}. The results are shown in Figure \ref{fig:difficulty-plot}. We observe that whenever it is difficult to perform the task using \textit{Nanni et al. (Sentence)}, entity salience supports our L2R system (Subset-2 and Subset-4).


\paragraph{\textbf{Conclusions.}}
%\ld{Split between RQ1 (salience) and RQ3 (right entities)?}
With respect to RQ1, we can say that entity salience does indeed affect the task positively. We are able to outperform all the baselines with the help of salience and we see that salience helps to boost performance when the queries get difficult by learning information which is complimentary to the lexical and semantic features. With respect to RQ4, exactly matching entities between context and aspect content leads to finding no matches for most aspects and hence most aspects receive a score of zero. Added to this are the limitations of SWAT in finding salient entities. Hence, entity salience is helpful but needs to be balanced with additional entities to be effective. 

%\ld{replace with "but needs to be balanced with additional entities to be effective": }we need to know how to use it to help our task.

%We are able to outperform all the baselines with the help of salience and we see that salience helps to boost performance when the queries get difficult. However, SWAT is still limited in its salience detection and this hinders the performance of a system using it. 

%\textbf{RQ2: Entity Relatedness.}
\subsection{RQ2: Entity Relatedness}
\label{subsec:Entity Relatedness}

\paragraph{\textbf{Observations.}}
We observe the following from Table \ref{tab:Results-shubham}.
\begin{enumerate}
    \item A supervised combination of all relatedness features (Subset-1) does not perform very well on its own, doing better than only one baseline (Size).
    \item However, a combination of relatedness features with the lexical and semantic features (Subset-3) does significantly better than three of the four baselines.
    \item Moreover, a combination of salience and relatedness features with the lexical and semantic features outperforms all baselines. 
\end{enumerate}


%We observe from Table \ref{tab:Results-shubham} that a supervised combination of all relatedness features (Subset-1) does not perform very well on its own, doing better than only one baseline (Size). However, a combination of relatedness features with the lexical and semantic features (Subset-3) does significantly better than three of the four baselines. Moreover, a combination of salience and relatedness features with the lexical and semantic features outperforms all baselines. 

\paragraph{\textbf{Discussions.}}
These observations indicate that entity relatedness does indeed affect the task positively. However, salience is more informative than relatedness as is evident from the superior performance of Subset-2 over Subset-1 and Subset-4 over Subset-3. On further investigation, we found that WAT finds many false positives and false negatives. For example, given the entity list consisting of  \textit{World War I}, \textit{Vietnam War} and \textit{France}, it predicts that \textit{World War I} is related to \textit{Vietnam War} (false positive) but  unrelated to \textit{France} (false negative). This is because WAT does not take
the query or the context of the entity into account but makes predictions based on  graph-based features such as number of inlinks and outlinks to and from a particular entity node in a knowledge graph. 

To investigate the extent to which relatedness helps, we present results from the difficulty test explained in Section \ref{subsec:Entity Salience} in Figure \ref{fig:difficulty-plot}. We observe that whenever it is difficult to perform the task using \textit{Nanni et al. (Sentence)}, entity relatedness supports our L2R system (Subset-3 and Subset-5).


\paragraph{\textbf{Conclusions.}}
With respect to RQ2, we may say that relatedness does indeed affect the task positively. Although the relatedness of entities by itself may not perform very well, it shows its strength in a supervised combination with lexical and semantic features leading to performance improvements over several baselines. Moreover, a L2R system containing relatedness based features help to boost performance when queries get difficult. However, the limitations of WAT hinder the performance of a system using it. 

%considering relatedness features in combination with some lexical and semantic features can help the task. However, WAT is limited in its entity relatedness system where it finds many false positives and false negatives.


%\textbf{RQ3: Frequency vs Relatedness.}
\subsection{RQ3: Frequency vs Relatedness}
\label{subsec:Frequency vs Relatedness}

\paragraph{\textbf{Observations.}}
We observe the following from Table \ref{tab:Results-shubham}.
\begin{enumerate}
    \item Ranking aspects using \textit{SF-Dist (Sentence)} outperforms \textit{WF-Dist (Sentence)}, which in turn outperforms \textit{Rel-Dist (Sentence)}).
    \item \textit{RS-Asp-Freq-ECD} outperforms \textit{RS-Asp-Rel-ECD}.
\end{enumerate}

%From Table \ref{tab:Results-shubham}, we observe that ranking aspects using \textit{SF-Dist (Sentence)} outperforms \textit{WF-Dist (Sentence)}, which in turn outperforms \textit{Rel-Dist (Sentence)}). Moreover, \textit{RS-Asp-Freq-ECD} outperforms \textit{RS-Asp-Rel-ECD}. 
We also find that when L2R is trained on all relatedness features (Subset-1), it places more weight on the features using frequency distribution those using relatedness. 

\paragraph{\textbf{Discussions.}}
These observations indicate that using the frequency of co-occurring entities is more informative than the relatedness. To investigate this further and to answer RQ4, as in Section \ref{subsec:Entity Salience}, we produce entity rankings for every aspect using:
\begin{enumerate}
    \item Frequency (SF-Dist in Section \ref{subsec:Entity Relatedness for Aspect Linking}(1))
    \item Relatedness (Rel-Dist in Section \ref{subsec:Entity Relatedness for Aspect Linking}(3))
\end{enumerate}
of entities and evaluate these rankings by defining all entities in an aspect as relevant for the aspect. The results are shown in Table \ref{tab:Results-Entity-Rankings-Freq-And-Rel}.

From Table \ref{tab:Results-Entity-Rankings-Freq-And-Rel}, we observe that the entity rankings obtained using frequency distribution (prominence) are indeed better (in terms of Mean Average Precision (MAP)) than those obtained using relatedness. For example, entity ranking obtained using section context and frequency distribution has $\text{MAP}=0.13$ whereas that obtained using relatedness has $\text{MAP}=0.04$. We also perform an additional experiment where we analyse the number of aspects that were helped (in terms of MAP) by using frequency distribution of co-occurring entities as compared to using the relatedness distribution. The results are shown in Table \ref{tab:Helps-Hurts-Analysis}. We observe, for example, that using frequency with section context helps 1160 aspects while hurting just 3 as compared to using relatedness. This shows why the entity ranking obtained using frequency and section context performs better than that obtained using relatedness in Table \ref{tab:Results-Entity-Rankings-Freq-And-Rel},and consequently, why the \textit{SF-Dist} methods perform better than the \textit{Rel-Dist} method in Table \ref{tab:Results-shubham}.

\paragraph{\textbf{Conclusions.}}
With respect to RQ3, we may say that using frequency of co-occurring entities is better than using relatedness because most frequently co-occurring entities are also related but most related entities do not frequently co-occur. With respect to RQ2, although relatedness can help when the queries get difficult, as compared to frequency, it hurts the performance of a method using it. 

